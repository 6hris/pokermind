{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173e2309-a47e-4d16-819b-7e33f67e4e52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac5f8f85f6e4172aabe96a5e9768d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce33fb10cea4b1cbbc3d8ed1eee74ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)lop_500k_train_set_prompt_and_label.json:   0%|          | 0.00/607M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4116b049bfe24df2b9b7b4e477186a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)flop_60k_train_set_prompt_and_label.json:   0%|          | 0.00/62.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b453b8537f4b3e97bb255fb8a5d266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)tflop_10k_test_set_prompt_and_label.json:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2454187d77047b28b3e18d17a4eb117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)reflop_1k_test_set_prompt_and_label.json:   0%|          | 0.00/965k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c975f1bb4d484489e0efd02b46bea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/563200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8fe666df1c48cf99bf2ebe4c5b0bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"RZ412/PokerBench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "397779d8-3c77-420e-9371-9f8d621fe817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (563200, 2), 'test': (11000, 2)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67208356-9f19-4d26-85d3-32ee2033ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "ds_key = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "223fa0f2-5abc-4370-8189-1e3e18f951b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d7f4349-6b56-4764-af13-af0a6129a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def query_llm(prompt, model):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "       # \"temperature\": 0.1,\n",
    "        #\"top_p\": 0.95\n",
    "    }\n",
    "    response = requests.post(\"https://openrouter.ai/api/v1/completions\", headers=headers, json=payload)\n",
    "    response_data = response.json()\n",
    "    if \"choices\" not in response_data:\n",
    "        print(response_data)\n",
    "        return\n",
    "    txt = response.json()[\"choices\"][0][\"text\"]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c119b41-291d-4615-8271-2d9fe752ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "\n",
    "def query_deepseek(prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-r1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            #temperature=0.1, \n",
    "            #top_p=0.95\n",
    "        )\n",
    "        print(\"deekseek response: \", response)\n",
    "        if response.choices:\n",
    "            return response.choices[0].message.content\n",
    "        else:\n",
    "            print(\"No response choices available.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying DeepSeek API: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41760969-10df-4b14-b6fc-2aec64db7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deepseek = \"deepseek/deepseek-r1\"\n",
    "model_llama = \"meta-llama/llama-3.3-70b-instruct\"\n",
    "model_gemini = \"google/gemini-2.0-flash-lite-preview-02-05:free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95e540b2-9b24-45b1-9b3b-3b19f1dce786",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = test_data['instruction']\n",
    "outputs = test_data['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa44518a-0f53-4613-b16f-b5368abdf9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your optimal action is: bet 4 chips.\n"
     ]
    }
   ],
   "source": [
    "ans = query_llm2(instructions[0])\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c778822-47f3-49d4-a5ed-4f270811c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "test_data_array = np.array(test_data)\n",
    "\n",
    "random_indices = np.random.choice(len(test_data_array), size=1000, replace=False)\n",
    "\n",
    "random_test_sample = test_data_array[random_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d017ff8c-7c1c-464e-a5d0-4180f0757f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Action: bet 4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_action(response):\n",
    "    # Define the regex pattern to match the action and optional value\n",
    "    pattern = r\"(bet|raise|call|fold|check)\\s*(\\d*)\"\n",
    "    \n",
    "    # Search for the pattern in the response\n",
    "    match = re.search(pattern, response, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        action = match.group(1).lower()  # Extract the action (e.g., \"bet\")\n",
    "        value = match.group(2) if match.group(2) else None  # Extract the value (e.g., \"4\")\n",
    "        \n",
    "        # Return the action and value (if applicable)\n",
    "        if value:\n",
    "            return f\"{action} {value}\"\n",
    "        else:\n",
    "            return action\n",
    "    else:\n",
    "        # If no action is found, return a fallback action (e.g., \"fold\")\n",
    "        return \"fold\"\n",
    "\n",
    "# Example usage\n",
    "response = \"Your optimal action is: bet 4 chips.\"\n",
    "extracted_action = extract_action(response)\n",
    "print(f\"Extracted Action: {extracted_action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "838f3a40-0dab-4f86-ac85-32f2862742ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check\n",
      "Check\n",
      "Check\n",
      "Bet 10 chips\n",
      "Check\n",
      "Call\n",
      "Call\n",
      "Check\n",
      "Call\n",
      "Call\n",
      "Call\n",
      "Bet 20 chips\n",
      "Check\n",
      "Check\n",
      "Check\n",
      "Fold\n",
      "Call\n",
      "Call\n",
      "Action Accuracy (AA): 83.33%\n",
      "Exact Match Accuracy (EM): 77.78%\n"
     ]
    }
   ],
   "source": [
    "instructions = test_data['instruction']\n",
    "outputs = test_data['output']\n",
    "\n",
    "predictions = [query_llm(instruction, model_gemini) for instruction in instructions[:18]]\n",
    "\n",
    "aa, em = evaluate_model(predictions, outputs[:18])\n",
    "\n",
    "print(f\"Action Accuracy (AA): {aa:.2f}%\")\n",
    "print(f\"Exact Match Accuracy (EM): {em:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8637e-9060-455d-b332-1f9b16e69d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
